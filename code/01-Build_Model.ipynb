{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Sentence Classification Model Building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse & clearn labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "tree = ET.parse('../data/Restaurants_Train.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'sentences' at 0x00000170B8F81C28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3044 reviews in this training set\n"
     ]
    }
   ],
   "source": [
    "# Use this dataframe for multilabel classification\n",
    "# Must use scikitlearn's multilabel binarizer\n",
    "\n",
    "labeled_reviews = []\n",
    "for sentence in root.findall(\"sentence\"):\n",
    "    entry = {}\n",
    "    aterms = []\n",
    "    aspects = []\n",
    "    if sentence.find(\"aspectTerms\"):\n",
    "        for aterm in sentence.find(\"aspectTerms\").findall(\"aspectTerm\"):\n",
    "            aterms.append(aterm.get(\"term\"))\n",
    "    if sentence.find(\"aspectCategories\"):\n",
    "        for aspect in sentence.find(\"aspectCategories\").findall(\"aspectCategory\"):\n",
    "            aspects.append(aspect.get(\"category\"))\n",
    "    entry[\"text\"], entry[\"terms\"], entry[\"aspects\"]= sentence[0].text, aterms, aspects\n",
    "    labeled_reviews.append(entry)\n",
    "labeled_df = pd.DataFrame(labeled_reviews)\n",
    "print(\"there are\",len(labeled_reviews),\"reviews in this training set\")\n",
    "#    print(sentence.find(\"aspectCategories\").findall(\"aspectCategory\").get(\"category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspects</th>\n",
       "      <th>terms</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[service]</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[service]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "      <td>[]</td>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           aspects                  terms  \\\n",
       "0                        [service]                [staff]   \n",
       "1  [food, anecdotes/miscellaneous]                 [food]   \n",
       "2                           [food]  [food, kitchen, menu]   \n",
       "3                        [service]                     []   \n",
       "4        [anecdotes/miscellaneous]                     []   \n",
       "\n",
       "                                                text  \n",
       "0               But the staff was so horrible to us.  \n",
       "1  To be completely fair, the only redeeming fact...  \n",
       "2  The food is uniformly exceptional, with a very...  \n",
       "3  Where Gabriela personaly greets you and recomm...  \n",
       "4  For those that go once and don't enjoy it, all...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save annotated reviews\n",
    "labeled_df.to_pickle(\"annotated_reviews_df.pkl\")\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with Naive Bayes\n",
    "1. replace pronouns with neural coref\n",
    "2. train the model with naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuralcoref import Coref\n",
    "import en_core_web_lg\n",
    "spacy = en_core_web_lg.load()\n",
    "coref = Coref(nlp=spacy)\n",
    "\n",
    "# Define function for replacing pronouns using neuralcoref\n",
    "def replace_pronouns(text):\n",
    "    coref.one_shot_coref(text)\n",
    "    return coref.get_resolved_utterances()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspects</th>\n",
       "      <th>terms</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[service]</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           aspects                  terms  \\\n",
       "0                        [service]                [staff]   \n",
       "1  [food, anecdotes/miscellaneous]                 [food]   \n",
       "2                           [food]  [food, kitchen, menu]   \n",
       "\n",
       "                                                text  \n",
       "0               But the staff was so horrible to us.  \n",
       "1  To be completely fair, the only redeeming fact...  \n",
       "2  The food is uniformly exceptional, with a very...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read annotated reviews df, which is the labeled dataset for training\n",
    "# This is located in the pickled files folder\n",
    "annotated_reviews_df = pd.read_pickle(\"../pickled_files/annotated_reviews_df.pkl\")\n",
    "annotated_reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replace_pronouns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a58cc877df70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a new column for text whose pronouns have been replaced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mannotated_reviews_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text_pro\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotated_reviews_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mreplace_pronouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   2994\u001b[0m         \"\"\"\n\u001b[0;32m   2995\u001b[0m         new_values = super(Series, self)._map_values(\n\u001b[1;32m-> 2996\u001b[1;33m             arg, na_action=na_action)\n\u001b[0m\u001b[0;32m   2997\u001b[0m         return self._constructor(new_values,\n\u001b[0;32m   2998\u001b[0m                                  index=self.index).__finalize__(self)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \u001b[1;31m# mapper is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src\\inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-a58cc877df70>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a new column for text whose pronouns have been replaced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mannotated_reviews_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text_pro\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotated_reviews_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mreplace_pronouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'replace_pronouns' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a new column for text whose pronouns have been replaced\n",
    "annotated_reviews_df[\"text_pro\"] = annotated_reviews_df.text.map(lambda x: replace_pronouns(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below to pickle the new df\n",
    "# annotated_reviews_df.to_pickle(\"annotated_reviews_df2.pkl\")\n",
    "\n",
    "# Read pickled file with replaced pronouns if it exists already\n",
    "annotated_reviews_df = pd.read_pickle(\"annotated_reviews_df2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Convert the multi-labels into arrays\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(annotated_reviews_df.aspects)\n",
    "X = annotated_reviews_df.text_pro\n",
    "\n",
    "# Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# save the the fitted binarizer labels\n",
    "# This is important: it contains the how the multi-label was binarized, so you need to\n",
    "# load this in the next folder in order to undo the transformation for the correct labels.\n",
    "filename = 'mlb.pkl'\n",
    "pickle.dump(mlb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "import numpy as np\n",
    "\n",
    "# LabelPowerset allows for multi-label classification\n",
    "# Build a pipeline for multinomial naive bayes classification\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1, 1))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-1))),])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if SVM performs better\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', LabelPowerset(\n",
    "                             SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, max_iter=6, random_state=42)))])\n",
    "_ = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "np.mean(predicted_svm == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Train naive bayes on full dataset and save model\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1, 1))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-1))),])\n",
    "text_clf = text_clf.fit(X, y)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'naive_model1.pkl'\n",
    "pickle.dump(text_clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can move on to 02-Sentiment analysis notebook, which will load the fitted Naive bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlb.inverse_transform(predicted)\n",
    "pred_df = pd.DataFrame(\n",
    "    {'text_pro': X_test,\n",
    "     'pred_category': mlb.inverse_transform(predicted)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some scrap code below which wasn't used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated reviews\n",
    "labeled_df.to_pickle(\"annotated_reviews_df.pkl\")\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was for parsing out terms & their relations to aspects\n",
    "# However, the terms were not always hyponyms of the aspects, so they were unusable\n",
    "aspects = {\"food\":[],\"service\":[],\"anecdotes/miscellaneous\":[], \"ambience\":[], \"price\":[]}\n",
    "for i in range(len(labeled_df)):\n",
    "    if len(labeled_df.aspects[i]) == 1:\n",
    "        if labeled_df.terms[i] != []:\n",
    "            for terms in labeled_df.terms[i]:\n",
    "                aspects[labeled_df.aspects[i][0]].append(terms.lower())\n",
    "for key in aspects:\n",
    "    aspects[key] = list(set(aspects[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = []\n",
    "for i in labeled_df.terms:\n",
    "    for j in i:\n",
    "        if j not in terms:\n",
    "            terms.append(j)\n",
    "print(\"there are\", len(terms),\"unique terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dataframe if doing the classifications separately as binary classifications\n",
    "labeled_reviews2 = []\n",
    "for sentence in root.findall(\"sentence\"):\n",
    "    entry = {\"food\":0,\"service\":0,\"anecdotes/miscellaneous\":0, \"ambience\":0, \"price\":0}\n",
    "    aterms = []\n",
    "    aspects = []\n",
    "    if sentence.find(\"aspectTerms\"):\n",
    "        for aterm in sentence.find(\"aspectTerms\").findall(\"aspectTerm\"):\n",
    "            aterms.append(aterm.get(\"term\"))\n",
    "    if sentence.find(\"aspectCategories\"):\n",
    "        for aspect in sentence.find(\"aspectCategories\").findall(\"aspectCategory\"):\n",
    "            if aspect.get(\"category\") in entry.keys():\n",
    "                entry[aspect.get(\"category\")] = 1\n",
    "    entry[\"text\"], entry[\"terms\"] = sentence[0].text, aterms\n",
    "    labeled_reviews2.append(entry)\n",
    "labeled_df2 = pd.DataFrame(labeled_reviews2)\n",
    "#    print(sentence.find(\"aspectCategories\").findall(\"aspectCategory\").get(\"category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df2.iloc[:,:5].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
